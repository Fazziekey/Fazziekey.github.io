
- **[2025.4.10]**  We released Seed-Thinking-v1.5: Advancing Superb Reasoning Models with Reinforcement Learning <a href="https://seed.bytedance.com/en/public_papers/seed-thinking-v1-5-advancing-superb-reasoning-models-with-reinforcement-learning?view_from=homepage_recommend">[Blog]</a> | <a href="https://arxiv.org/abs/2504.13914">[Paper]</a>

- **[2025.4.03]**  We released VeOmni: Scaling any Modality Model Training to any Accelerators with PyTorch native Training Framework <a href="https://github.com/ByteDance-Seed/VeOmni">[Code]</a>

- **[2025.1.25]**  We released UI-TARS: Pioneering Automated GUI Interaction with Native Agents, ðŸ¤— <a href="https://huggingface.co/bytedance-research/UI-TARS-7B-DPO">Hugging Face Models</a> | ðŸ¤– <a href="https://github.com/bytedance/UI-TARS/tree/main">Code</a> | ðŸ“‘ <a href="https://arxiv.org/abs/2501.12326">Paper</a> | <a href="https://team.doubao.com/en/publication/ui-tars-pioneering-automated-gui-interaction-with-native-agents?view_from=homepage_recommend">Report</a>

- **[2025.1.22]** Doubao-1.5-pro released <a href="https://team.doubao.com/zh/special/doubao_1_5_pro">[Link]</a>

- **[2024.5.5]** Our Paper "InfiAgent-DABench: Evaluating Agents on Data Analysis Tasks" is accepted by ICML 2024

- **[2023.3.29]** We released Coati(Colossal AI Talking intelligence): An Open-Source Solution for Cloning ChatGPT With a Complete RLHF Pipeline, <a href="https://medium.com/@yangyou_berkeley/colossalchat-an-open-source-solution-for-cloning-chatgpt-with-a-complete-rlhf-pipeline-5edf08fb538b">[Link]</a>

- **[2023.2.22]** My work for stable diffusion training acceleration was officially reposted by Pytorch, <a href="https://www.hpc-ai.tech/blog/colossal-ai-chatgpt">[Link]</a> 

- **[2023.2.14]** We released an open source solution that replicates ChatGPT training process! Ready to go with only 1.6GB GPU Memory, <a href="https://twitter.com/PyTorch/status/1628076104626974732?t=y656lK4VtI4EC3WkgaKPbQ&s=19">[Link]</a>

- **[2023.1.31]** We support the stable diffusion v2 with Colossal-AI, <a href="https://medium.com/pytorch/latest-colossal-ai-boasts-novel-automatic-parallelism-and-offers-savings-up-to-46x-for-stable-1453b48f3f02">Latest Colossal-AI boasts novel automatic parallelism and offers savings up to 46x for Stable Diffusion 2</a>

- **[2022.11.9]** We have open sourced the stable diffusion training acceleration solution with Colossal-AI. <a href="https://medium.com/@yangyou_berkeley/diffusion-pretraining-and-hardware-fine-tuning-can-be-almost-7x-cheaper-85e970fe207b">Diffusion Pretraining and Hardware Fine-Tuning Can Be Almost 7X Cheaper! Colossal-AI's Open Source Solution Accelerates AIGC at a Low Cost</a>