- **[2024.5.5]** Our Paper "InfiAgent-DABench: Evaluating Agents on Data Analysis Tasks" is accepted by ICML 2024

- **[2023.3.29]** We released Coati(Colossal AI Talking intelligence): An Open-Source Solution for Cloning ChatGPT With a Complete RLHF Pipeline, <a href="https://medium.com/@yangyou_berkeley/colossalchat-an-open-source-solution-for-cloning-chatgpt-with-a-complete-rlhf-pipeline-5edf08fb538b">[Link]</a>

- **[2023.2.22]** My work for stable diffusion training acceleration was officially reposted by Pytorch, <a href="https://www.hpc-ai.tech/blog/colossal-ai-chatgpt">[Link]</a> 

- **[2023.2.14]** We released an open source solution that replicates ChatGPT training process! Ready to go with only 1.6GB GPU Memory, <a href="https://twitter.com/PyTorch/status/1628076104626974732?t=y656lK4VtI4EC3WkgaKPbQ&s=19">[Link]</a>

- **[2023.1.31]** We support the stable diffusion v2 with Colossal-AI, <a href="https://medium.com/pytorch/latest-colossal-ai-boasts-novel-automatic-parallelism-and-offers-savings-up-to-46x-for-stable-1453b48f3f02">Latest Colossal-AI boasts novel automatic parallelism and offers savings up to 46x for Stable Diffusion 2</a>

- **[2022.11.9]** We have open sourced the stable diffusion training acceleration solution with Colossal-AI. <a href="https://medium.com/@yangyou_berkeley/diffusion-pretraining-and-hardware-fine-tuning-can-be-almost-7x-cheaper-85e970fe207b">Diffusion Pretraining and Hardware Fine-Tuning Can Be Almost 7X Cheaper! Colossal-AI's Open Source Solution Accelerates AIGC at a Low Cost</a>